{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Programapython/detector_osteoartritis/blob/main/practicas/practica1/Pr%C3%A1ctica_1_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# TensorFlow - Hola mundo!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsmULAsYPHhE"
      },
      "source": [
        "**La base de datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "Fyh0H7aaPQQ5",
        "outputId": "bee07408-4e92-494f-a3a0-929881e36415"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"600\"\n",
              "            src=\"https://www.kaggle.com/datasets/salil007/caavo\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x79c564390df0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import IFrame\n",
        "url = \"https://www.kaggle.com/datasets/salil007/caavo\"\n",
        "IFrame(url, width=800, height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnrWf3PCEzXL"
      },
      "source": [
        "## Preparación de TensorFlow\n",
        "\n",
        "Importamos TensorFlow al programa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0trJmd6DjqBZ",
        "outputId": "2fa8527f-e806-4d2a-ca5a-686a5bb6294d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.17.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okfSeA2mNhOP"
      },
      "source": [
        "Importamos la librería opendatasets para descargar conjuntos de datos de Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rm4HhqF8MW7p",
        "outputId": "debdac2e-459a-431d-c562-bd430f1b35f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.5)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.10)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets\n",
        "import opendatasets as od"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "## Carga de un conjunto de datos\n",
        "\n",
        "[Clothes Classification](https://www.kaggle.com/datasets/salil007/caavo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHAbEcZiMOdN",
        "outputId": "473586ce-2d9a-4457-82da-9441f19c75fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: wjsl13\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/salil007/caavo\n",
            "Downloading caavo.zip to ./caavo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 618M/618M [00:17<00:00, 36.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "dataset = \"https://www.kaggle.com/datasets/salil007/caavo\"\n",
        "od.download(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6hecOZOPehq"
      },
      "source": [
        "Configuración de la data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY5r_JV9Qish",
        "outputId": "a9f07107-b1c2-414d-bd99-8941ac03aa5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['train', 'samp_sub.csv', 'test']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/caavo\")\n",
        "os.listdir(\"/content/caavo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pqXEKqrERFwg",
        "outputId": "20cd8895-9465-4e55-cd80-76646ca1ea41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se procesaron 62258 imágenes con tamaño (224, 224) cada una.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def procesar_imagenes(folder_path, target_size=(224, 224)):\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "    imagenes_procesadas = []\n",
        "\n",
        "    for filename in image_files:\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        img = cv2.resize(img, target_size)\n",
        "\n",
        "        imagenes_procesadas.append(img)\n",
        "\n",
        "    return np.array(imagenes_procesadas)\n",
        "\n",
        "folder_path = '/content/caavo/train/train/'\n",
        "\n",
        "imagenes_procesadas = procesar_imagenes(folder_path)\n",
        "\n",
        "print(f\"Se procesaron {imagenes_procesadas.shape[0]} imágenes con tamaño {imagenes_procesadas.shape[1:]} cada una.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "7FP5258xjs-v",
        "outputId": "8ace1ca5-5677-4180-9860-7087b5c24799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7bfaab8eeb60>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "plt.imshow(x_train[1], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "## Creación de un modelo de aprendizaje automático\n",
        "\n",
        "Cree un modelo `tf.keras.Sequential`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3IKyzTCDNGo",
        "outputId": "c4f5a68c-f6e9-4671-e2e2-22533896ce1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "  tf.keras.layers.Flatten(input_shape=(32, 32,3)),\n",
        "\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "  tf.keras.layers.Dense(100)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2hiez2eIUz8"
      },
      "source": [
        "[`Sequential`](https://www.tensorflow.org/guide/keras/sequential_model) es útil para apilar capas donde cada una tiene un [tensor](https://www.tensorflow.org/guide/tensor) de entrada y uno de salida. Las capas son funciones con una estructura matemática desconocida que se puede reutilizar y que tiene variables entrenables. La mayoría de los modelos TensorFlow están compuestos por capas. Este modelo usa las capas [`Flatten`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten), [`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) y [`Dropout`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout).\n",
        "\n",
        "Para cada ejemplo, el modelo devuelve un vector de [logits](https://developers.google.com/machine-learning/glossary#logits) o puntajes de [log-odds](https://developers.google.com/machine-learning/glossary#log-odds) (registro de probabilidades) por cada clase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeOrNdnkEEcR",
        "outputId": "0c0751dd-b59f-4cca-9ad3-49d353399256"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.18478662,  0.16266268,  0.15657592,  1.3735139 ,  0.48021877,\n",
              "        -0.41910285, -0.59568036,  0.50237054,  0.20089337,  0.69678557,\n",
              "         1.032598  , -0.62536263,  0.13896737,  0.47836155, -0.9402652 ,\n",
              "        -0.0514926 , -1.1528369 , -0.5863404 ,  0.27686107,  0.4155635 ,\n",
              "        -0.70588505, -0.11056677,  0.30232334,  0.71741086, -1.1478113 ,\n",
              "        -0.5842693 , -0.9835627 , -0.5640001 , -0.28173906, -0.7107874 ,\n",
              "        -0.12204459, -0.41069835,  0.39589465, -1.9365305 , -0.24432781,\n",
              "         0.36065966,  1.2570717 , -1.2818315 ,  0.5169447 , -0.9592601 ,\n",
              "        -0.30764246,  0.5784672 ,  0.12360495, -0.3634019 , -0.67253244,\n",
              "        -0.22579384,  0.47982514, -0.12007391,  0.3308771 , -0.094229  ,\n",
              "        -0.41482484,  0.7490312 , -0.2756874 ,  0.03961388,  1.2256699 ,\n",
              "        -0.312816  ,  0.74362457, -0.2804219 ,  0.32960644,  1.032596  ,\n",
              "         0.06312904,  0.02149136,  0.6638867 , -0.4484217 ,  1.4431188 ,\n",
              "        -0.23446865, -0.07666175, -1.1603504 , -0.22595493,  0.51803434,\n",
              "         0.5400004 ,  0.44044608,  0.4182389 , -0.04290238,  1.1225494 ,\n",
              "         0.44748017, -0.6778967 ,  0.17239228, -0.7254475 ,  0.42539895,\n",
              "         0.3636952 ,  0.78466487, -0.7982348 ,  0.05078711,  0.3105073 ,\n",
              "         0.3601399 ,  0.80253136,  0.9432056 ,  0.11612987, -0.6251598 ,\n",
              "         0.02735077, -0.03172618, -0.34153014, -0.53057766, -0.11917681,\n",
              "         0.5592452 ,  0.77403593,  0.28762436, -0.05910355, -0.31224543]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = model(x_train[:1]).numpy()\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgjhDQGcIniO"
      },
      "source": [
        "La función `tf.nn.softmax` convierte estas funciones logits en *probabilidades* para cada clase:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWSRnQ0WI5eq",
        "outputId": "2a4c6ee0-9dde-4313-89f8-de1959a21ef9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.00668673, 0.00946475, 0.00940732, 0.03176693, 0.01300236,\n",
              "        0.00528995, 0.00443369, 0.0132936 , 0.0098336 , 0.0161464 ,\n",
              "        0.02259006, 0.00430402, 0.00924312, 0.01297823, 0.00314133,\n",
              "        0.00764017, 0.00253977, 0.00447529, 0.01060975, 0.01218828,\n",
              "        0.00397103, 0.0072019 , 0.01088336, 0.01648289, 0.00255257,\n",
              "        0.00448457, 0.00300822, 0.0045764 , 0.00606887, 0.00395161,\n",
              "        0.00711971, 0.0053346 , 0.0119509 , 0.00115996, 0.00630022,\n",
              "        0.01153714, 0.02827516, 0.00223241, 0.01348876, 0.00308222,\n",
              "        0.00591369, 0.01434468, 0.00910221, 0.00559297, 0.00410571,\n",
              "        0.00641807, 0.01299724, 0.00713376, 0.0111986 , 0.00732053,\n",
              "        0.00531263, 0.01701241, 0.00610571, 0.00836893, 0.02740106,\n",
              "        0.00588317, 0.01692068, 0.00607687, 0.01118438, 0.02259001,\n",
              "        0.00856806, 0.00821863, 0.01562385, 0.00513711, 0.03405683,\n",
              "        0.00636264, 0.00745027, 0.00252076, 0.00641704, 0.01350346,\n",
              "        0.01380336, 0.01249537, 0.01222094, 0.00770608, 0.02471626,\n",
              "        0.01258357, 0.00408375, 0.00955729, 0.00389411, 0.01230875,\n",
              "        0.01157221, 0.01762955, 0.00362074, 0.00846296, 0.0109728 ,\n",
              "        0.01153115, 0.01794736, 0.0206583 , 0.00903442, 0.00430489,\n",
              "        0.00826692, 0.00779269, 0.00571664, 0.00473193, 0.00714016,\n",
              "        0.01407158, 0.01744316, 0.01072456, 0.00758224, 0.00588653]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.nn.softmax(predictions).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he5u_okAYS4a"
      },
      "source": [
        "Nota: es posible aplicar la función `tf.nn.softmax` en la función de activación para la última capa de la red. Si bien esto puede hacer que la salida del modelo se interprete más directamente, este enfoque no se recomienda ya que es imposible proporcionar un cálculo de pérdida numéricamente estable y exacto para todos los modelos con salida softmax."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQyugpgRIyrA"
      },
      "source": [
        "Defina la función de pérdida para el entrenamiento con `losses.SparseCategoricalCrossentropy`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obtIM5geZPYP"
      },
      "source": [
        "[Cross entropía binaria](https://www.v7labs.com/blog/cross-entropy-loss-guide)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2q1vAENd9rF",
        "outputId": "575bac82-e11e-49ff-d7d7-2c2801623d88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[19],\n",
              "       [29],\n",
              "       [ 0],\n",
              "       ...,\n",
              "       [ 3],\n",
              "       [ 7],\n",
              "       [73]])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSkzdv8MD0tT"
      },
      "outputs": [],
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfR4MsSDU880"
      },
      "source": [
        "La función de pérdida toma un vector de valores verdaderos de base y un vector de logits y devuelve una pérdida escalar para cada ejemplo. Esta pérdida es igual a la probabilidad de registro negativa de la clase verdadera: La pérdida es cero si el modelo está seguro de la clase correcta.\n",
        "\n",
        "El modelo sin entrenar arroja probabilidades cercanas al lo aleatorio (1/10 para cada clase), entonces, la pérdida inicial debería estar cerca de `-tf.math.log(1/10) ~= 2.3`.\n",
        "\n",
        "La entrópia cruzada para un modelo no entrenado `Pérdida=−log(y)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN5pj_ITbJkS",
        "outputId": "fe57f800-8b86-4ef7-a49f-72e5984456a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[71]]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[y_train[:1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJWqEVrrJ7ZB",
        "outputId": "0eee71a8-89a5-4773-c2fa-465c9ce6e8a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.40728"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss_fn(y_train[:1], predictions).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ada44eb947d4"
      },
      "source": [
        "Antes de empezar el entrenamiento, configure y compile el modelo con Keras `Model.compile`. Configure la clase del [`optimizador`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) como `adam`, establezca `loss` para la función `loss_fn` que definió antes y especifique una métrica a evaluar para el modelo, mediante la determinación del parámetro `metrics` para `accuracy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9foNKHzTD2Vo"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,),\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4mEL65on-w"
      },
      "source": [
        "## Entrenamiento y evaluación del modelo\n",
        "\n",
        "Use el método `Model.fit` para ajustar los parámetros del modelo y minimizar la pérdida:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7suUbJXVLqP",
        "outputId": "e074d171-a561-44d6-a220-ca6c2855024e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.0332 - loss: 4.3402\n",
            "Epoch 2/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.0321 - loss: 4.3339\n",
            "Epoch 3/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.0334 - loss: 4.3343\n",
            "Epoch 4/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0325 - loss: 4.3323\n",
            "Epoch 5/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0325 - loss: 4.3376\n",
            "Epoch 6/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.0322 - loss: 4.3287\n",
            "Epoch 7/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.0337 - loss: 4.3209\n",
            "Epoch 8/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.0354 - loss: 4.3159\n",
            "Epoch 9/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0345 - loss: 4.3138\n",
            "Epoch 10/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.0365 - loss: 4.2997\n",
            "Epoch 11/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0369 - loss: 4.3025\n",
            "Epoch 12/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.0372 - loss: 4.2879\n",
            "Epoch 13/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.0398 - loss: 4.2800\n",
            "Epoch 14/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.0392 - loss: 4.2813\n",
            "Epoch 15/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0429 - loss: 4.2596\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bfaab80f610>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mDAAPFqVVgn"
      },
      "source": [
        "El método `Model.evaluate` controla el desempeño del modelo, por lo general con un [conjunto de evaluación](https://developers.google.com/machine-learning/glossary#validation-set) o un [conjunto de prueba](https://developers.google.com/machine-learning/glossary#test-set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7dTAzgHDUh7",
        "outputId": "f8bdb9cc-5b07-40d0-8e5b-2001f7edfe16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 - 1s - 2ms/step - accuracy: 0.0606 - loss: 4.1392\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[4.139200687408447, 0.060600001364946365]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(x_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4JfEh7kvx6m"
      },
      "source": [
        "El clasificador de imágenes ahora está entrenado para proporcionar ~98% de exactitud en este conjunto de datos. Para más información, lea los [tutoriales de TensorFlow](https://www.tensorflow.org/tutorials/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj8NrlzlJqDG"
      },
      "source": [
        "Si desea que su modelo devuelva una probabilidad, puede empaquetar el modelo entrenado y adjuntarle el softmax:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYb6DrEH0GMv"
      },
      "outputs": [],
      "source": [
        "probability_model = tf.keras.Sequential([\n",
        "  model,\n",
        "  tf.keras.layers.Softmax()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnqOZtUp1YR_",
        "outputId": "b8baf5cb-649b-40bb-9c8d-4cbd444235ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
              "array([[1.04825020e-04, 9.13500693e-03, 3.78441229e-03, 3.00522265e-03,\n",
              "        4.29385900e-03, 9.51342285e-03, 1.25326391e-03, 1.51599103e-04,\n",
              "        1.40807936e-02, 3.52860405e-03, 4.60137799e-03, 5.79677895e-03,\n",
              "        3.13310474e-02, 2.18052454e-02, 3.62323626e-04, 1.13904728e-02,\n",
              "        3.29902745e-03, 1.75018897e-04, 1.07719889e-03, 1.03971893e-02,\n",
              "        8.06189841e-04, 7.25376792e-03, 7.19553232e-03, 3.83492969e-02,\n",
              "        2.96295948e-05, 9.58812702e-03, 2.11571506e-03, 5.41584566e-03,\n",
              "        5.07400697e-03, 6.28682273e-03, 4.61662225e-02, 5.29566256e-04,\n",
              "        1.90755986e-02, 1.27424952e-02, 1.54481549e-03, 5.27547952e-03,\n",
              "        3.43630370e-03, 1.99799184e-02, 3.84032167e-03, 1.90653410e-02,\n",
              "        9.60110407e-03, 1.47291878e-03, 2.58413726e-03, 5.50128461e-04,\n",
              "        2.57688598e-03, 2.17277929e-03, 1.11692473e-02, 8.44174938e-04,\n",
              "        8.70533288e-03, 4.22615819e-02, 2.92757596e-03, 4.18201089e-03,\n",
              "        8.36296067e-07, 6.48682499e-06, 9.92430747e-03, 8.52676760e-03,\n",
              "        2.00913921e-02, 6.04504603e-04, 1.52183603e-02, 2.66128656e-04,\n",
              "        1.55621208e-02, 6.70203613e-03, 1.30475336e-03, 7.31693697e-04,\n",
              "        5.14149806e-03, 6.38463674e-03, 3.05192824e-03, 2.67960262e-02,\n",
              "        3.06076817e-02, 4.97485138e-02, 3.07784835e-03, 4.36066017e-02,\n",
              "        1.70435030e-02, 5.11970147e-02, 4.39247349e-04, 1.48098613e-03,\n",
              "        4.68847118e-02, 1.79777900e-03, 1.47925131e-03, 4.13665362e-03,\n",
              "        2.91711232e-03, 1.36763817e-02, 1.54441397e-04, 7.32665649e-05,\n",
              "        5.19706262e-03, 1.16276145e-02, 2.67401966e-03, 8.63885600e-03,\n",
              "        4.07544168e-04, 7.11270003e-03, 1.68965831e-02, 1.30820591e-02,\n",
              "        2.42265081e-03, 3.02025303e-02, 3.76704527e-04, 5.00043072e-02,\n",
              "        1.50098151e-03, 4.34290571e-03, 3.90232727e-03, 1.10710701e-02]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probability_model(x_test[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-47O6_GLdRuT"
      },
      "source": [
        "## Conclusión\n",
        "\n",
        "¡Felicitaciones! Ha entrenado un modelo de entrenamiento automático con un conjunto de datos predeterminado usando la API [Keras](https://www.tensorflow.org/guide/keras/overview).\n",
        "\n",
        "Para acceder a más ejemplos sobre el uso de Keras, consulte los [tutoriales](https://www.tensorflow.org/tutorials/keras/). Para más información sobre cómo crear modelos con Keras, lea las [guías](https://www.tensorflow.org/guide/keras). Si quiere aprender más sobre cómo cargar y preparar los datos, mire los tutoriales sobre [carga de datos de imágenes](https://www.tensorflow.org/tutorials/load_data/images) o [carga de datos CSV](https://www.tensorflow.org/tutorials/load_data/csv).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}